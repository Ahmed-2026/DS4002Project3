# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kik0XbUNXIyVOoAoQq5-WTU3bBRuqXCS
"""

!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz
!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz

!tar -xvf images.tar.gz
!tar -xvf annotations.tar.gz

import os
print("Number of images:", len(os.listdir("images")))

import os

print("Working directory:", os.listdir())
print("Images folder:", len(os.listdir("images")), "files")
print("Annotations folder:", os.listdir("annotations")[:10])

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

ANNOT_PATH = "list.txt"
IMG_FOLDER = "images/"

rows = []
with open(ANNOT_PATH, "r") as f:
    for line in f:
        parts = line.strip().split()

        # Skip header or malformed lines
        if len(parts) < 3:
            continue
        if parts[0].lower() == "image":
            continue
        if not parts[1].isdigit() or not parts[2].isdigit():
            continue

        img_name = parts[0] + ".jpg"
        class_id = int(parts[1])
        species = int(parts[2])

        rows.append([img_name, class_id, species])

df = pd.DataFrame(rows, columns=["image", "class_id", "species"])
df["species_binary"] = df["species"].apply(lambda x: 0 if x == 1 else 1)

df.head()

train_df, test_df = train_test_split(df, test_size=0.15, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)

len(train_df), len(val_df), len(test_df)

IMG_SIZE = 224
BATCH_SIZE = 32

def load_image(path, label):
    img = tf.io.read_file(path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))
    return img / 255.0, label

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1)
])

def build_dataset(df, label_col, augment=False):
    paths = [os.path.join(IMG_FOLDER, img) for img in df["image"]]
    labels = df[label_col].values

    ds = tf.data.Dataset.from_tensor_slices((paths, labels))

    def load(path, label):
        img = tf.io.read_file(path)
        img = tf.image.decode_jpeg(img, channels=3)
        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))
        img = img / 255.0
        return img, label

    ds = ds.map(load, num_parallel_calls=tf.data.AUTOTUNE)

    # FIXED AUGMENTATION: apply ONLY after batching
    if augment:
        ds = ds.batch(BATCH_SIZE).map(
            lambda x, y: (data_augmentation(x, training=True), y),
            num_parallel_calls=tf.data.AUTOTUNE
        )
    else:
        ds = ds.batch(BATCH_SIZE)

    ds = ds.prefetch(tf.data.AUTOTUNE)
    return ds

train_ds = build_dataset(train_df, "species_binary")
train_ds_aug = build_dataset(train_df, "species_binary", augment=True)
val_ds = build_dataset(val_df, "species_binary")
test_ds = build_dataset(test_df, "species_binary")

def build_cnn(num_classes=2, use_aug=False):
    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

    x = inputs
    if use_aug:
        x = data_augmentation(x)

    base = tf.keras.applications.ResNet50(
        include_top=False,
        weights="imagenet",
        input_shape=(IMG_SIZE, IMG_SIZE, 3)
    )
    base.trainable = False

    x = tf.keras.applications.resnet.preprocess_input(x * 255)
    x = base(x, training=False)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dropout(0.25)(x)

    if num_classes == 2:
        outputs = tf.keras.layers.Dense(1, activation="sigmoid")(x)
        loss = "binary_crossentropy"
    else:
        outputs = tf.keras.layers.Dense(num_classes, activation="softmax")(x)
        loss = "sparse_categorical_crossentropy"

    model = tf.keras.Model(inputs, outputs)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-4),
        loss=loss,
        metrics=["accuracy"]
    )
    return model

baseline = build_cnn(num_classes=2)
history_base = baseline.fit(train_ds, validation_data=val_ds, epochs=3)

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
], name="data_augmentation")

data_augmentation.build((None, 224, 224, 3))

augmented = build_cnn(num_classes=2, use_aug=True)
history_aug = augmented.fit(train_ds_aug, validation_data=val_ds, epochs=3)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_binary(model, dataset, name="Model"):
    y_true, y_pred = [], []

    for images, labels in dataset:
        preds = (model.predict(images).ravel() > 0.5).astype(int)
        y_true.extend(labels.numpy())
        y_pred.extend(preds)

    print(f"\n{name} Classification Report:")
    print(classification_report(y_true, y_pred, target_names=["Cat", "Dog"]))

    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Cat", "Dog"],
                yticklabels=["Cat", "Dog"])
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

evaluate_binary(baseline, test_ds, "Baseline CNN")
evaluate_binary(augmented, test_ds, "Augmented CNN")

num_classes = df["class_id"].max() + 1

train_multi = build_dataset(train_df, "class_id", augment=True)
val_multi = build_dataset(val_df, "class_id")
test_multi = build_dataset(test_df, "class_id")
breed_model = build_cnn(num_classes=num_classes, use_aug=True)

history_breed = breed_model.fit(
    train_multi,
    validation_data=val_multi,
    epochs=5
)

y_true, y_pred = [], []

for images, labels in test_multi:
    preds = breed_model.predict(images)
    preds = np.argmax(preds, axis=1)

    y_true.extend(labels.numpy())
    y_pred.extend(preds)

print("\nMulticlass Classification Report:")
print(classification_report(y_true, y_pred))

